{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ba3e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1213c1",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e832f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAGGLE DATA\n",
    "seeds24 = pd.read_csv('2024_tourney_seeds.csv')\n",
    "mm_results = pd.read_csv('MNCAATourneyDetailedResults.csv')\n",
    "mm_seeds = pd.read_csv('MNCAATourneySeeds.csv')\n",
    "teams = pd.read_csv('MTeams.csv')\n",
    "team_spellings = pd.read_csv('MTeamSpellings.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ca8433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTSIDE DATA\n",
    "cbb = pd.read_csv('cbb.csv')\n",
    "cbb24 = pd.read_csv('cbb24.csv')\n",
    "kenpom = pd.read_csv('KenPom Barttorvik.csv')\n",
    "resumes = pd.read_csv('Resumes.csv')\n",
    "upsets = pd.read_csv('Upset Count.csv')\n",
    "\n",
    "kpi17 = pd.read_excel('KPI-Rankings_2017.xlsx')\n",
    "kpi18 = pd.read_excel('KPI-Rankings_2018.xlsx')\n",
    "kpi19 = pd.read_excel('KPI-Rankings_2019.xlsx')\n",
    "kpi21 = pd.read_excel('KPI-Rankings_2021.xlsx')\n",
    "kpi22 = pd.read_excel('KPI-Rankings_2022.xlsx')\n",
    "kpi23 = pd.read_excel('KPI-Rankings_2023.xlsx')\n",
    "kpi24 = pd.read_excel('KPI-Rankings_2024.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca63728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine KPI data frames\n",
    "kpi17 = kpi17[['KPI', 'Team', 'KPI #', 'SOS', 'SOS Rk']]\n",
    "kpi17['Year'] = '2017'\n",
    "kpi18 = kpi18[['KPI', 'Team', 'KPI #', 'SOS', 'SOS Rk']]\n",
    "kpi18['Year'] = '2018'\n",
    "kpi19 = kpi19[['KPI', 'Team', 'KPI #', 'SOS', 'SOS Rk']]\n",
    "kpi19['Year'] = '2019'\n",
    "kpi21 = kpi21[['KPI', 'Team', 'KPI #', 'SOS', 'SOS Rk']]\n",
    "kpi21['Year'] = '2021'\n",
    "kpi22 = kpi22[['KPI', 'Team', 'KPI #', 'SOS', 'SOS Rk']]\n",
    "kpi22['Year'] = '2022'\n",
    "kpi23 = kpi23[['KPI', 'Team', 'KPI #', 'SOS', 'SOS Rk']]\n",
    "kpi23['Year'] = '2023'\n",
    "\n",
    "kpi = pd.concat([kpi17, kpi18, kpi19, kpi21, kpi22, kpi23], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "558e9d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "kenpom24 = kenpom[kenpom['YEAR'] == 2024]\n",
    "resumes24 = resumes[resumes['YEAR'] == 2024]\n",
    "\n",
    "kenpom = kenpom[kenpom['YEAR'] != 2024]\n",
    "resumes = resumes[resumes['YEAR'] != 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba0f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIMITATIONS:\n",
    "\n",
    "# NET rankings only go back to 2021 tournament: https://stats.ncaa.org/selection_rankings/nitty_gritties\n",
    "# CBB rankings only go back to 2013 tournament\n",
    "# KPI rankings only go back to 2017 tournament: https://faktorsports.com/\n",
    "# 538 shut down for 2024, so can't use power ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53829e7d",
   "metadata": {},
   "source": [
    "# Merge Tournament Results Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28295bd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# isolate relevant columns\n",
    "mm_results = mm_results[['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore']]\n",
    "\n",
    "# merge team names to match ID's\n",
    "mm_results = mm_results.merge(teams, left_on='WTeamID', right_on='TeamID', how='left', suffixes=('', '_W'))\n",
    "mm_results = mm_results.merge(teams, left_on='LTeamID', right_on='TeamID', how='left', suffixes=('', '_L'))\n",
    "\n",
    "# isolate and rename relevant columns \n",
    "mm_results.drop(['TeamID', 'TeamID_L'], axis=1, inplace=True)\n",
    "mm_results.rename(columns={'TeamName': 'WTeamName', 'TeamName_L': 'LTeamName'}, inplace=True)\n",
    "mm_results.drop(['FirstD1Season', 'LastD1Season', 'FirstD1Season_L', 'LastD1Season_L'], axis=1, inplace=True)\n",
    "\n",
    "# filter for relevant matches\n",
    "year_mask = (mm_results['Season'] >= 2017)\n",
    "round_mask = (mm_results['DayNum'] >= 136)\n",
    "mm_results = mm_results[year_mask & round_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f56cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for round\n",
    "def get_round(day_num):\n",
    "    if day_num in [134, 135]:\n",
    "        return 'Play-in games'\n",
    "    elif day_num in [136, 137]:\n",
    "        return 'Round 1'\n",
    "    elif day_num in [138, 139]:\n",
    "        return 'Round 2'\n",
    "    elif day_num in [143, 144]:\n",
    "        return 'Round 3 (Sweet Sixteen)'\n",
    "    elif day_num in [145, 146]:\n",
    "        return 'Round 4 (Elite Eight)'\n",
    "    elif day_num == 152:\n",
    "        return 'Round 5 (Final Four)'\n",
    "    elif day_num == 154:\n",
    "        return 'Round 6 (National Final)'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "mm_results['Round'] = mm_results['DayNum'].apply(get_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77729b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove region from seeds data\n",
    "mm_seeds['Seed'] = mm_seeds['Seed'].apply(lambda x: int(x[1:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4705f8cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# merge tournament seeds onto teams\n",
    "mm_results = mm_results.merge(mm_seeds, left_on=['Season','WTeamID'], right_on=['Season','TeamID'], how='left', suffixes=('', '_W'))\n",
    "mm_results = mm_results.merge(mm_seeds, left_on=['Season','LTeamID'], right_on=['Season','TeamID'], how='left', suffixes=('', '_L'))\n",
    "\n",
    "# isolate and rename relevant columns \n",
    "mm_results.drop(['TeamID', 'TeamID_L'], axis=1, inplace=True)\n",
    "mm_results.rename(columns={'Seed': 'WSeed', 'Seed_L': 'LSeed'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3acfc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_teams(row):\n",
    "    sorted_names = sorted([row['WTeamName'], row['LTeamName']])\n",
    "    return pd.Series({'ATeamName': sorted_names[0], 'BTeamName': sorted_names[1]})\n",
    "\n",
    "new_columns = mm_results.apply(rename_teams, axis=1)\n",
    "mm_results = pd.concat([mm_results, new_columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "190d9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_team_info(row):\n",
    "    if row['WTeamName'] == row['ATeamName']:\n",
    "        return pd.Series({'ATeamID': row['WTeamID'], 'BTeamID': row['LTeamID'],\n",
    "                          'AScore': row['WScore'], 'BScore': row['LScore'],\n",
    "                          'ASeed': row['WSeed'], 'BSeed': row['LSeed']})\n",
    "    elif row['WTeamName'] == row['BTeamName']:\n",
    "        return pd.Series({'BTeamID': row['WTeamID'], 'ATeamID': row['LTeamID'],\n",
    "                          'BScore': row['WScore'], 'AScore': row['LScore'],\n",
    "                          'BSeed': row['WSeed'], 'ASeed': row['LSeed']})\n",
    "\n",
    "new_columns = mm_results.apply(match_team_info, axis=1)\n",
    "mm_results = pd.concat([mm_results, new_columns], axis=1)\n",
    "mm_results.drop(['WTeamName','LTeamName','WTeamID','LTeamID','WScore','LScore','WSeed','LSeed'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec65a70",
   "metadata": {},
   "source": [
    "# Merge Team Stats Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bf0ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = resumes[resumes['YEAR'] >= 2017]\n",
    "cbb = cbb[cbb['YEAR'] >= 2017]\n",
    "kenpom = kenpom[(kenpom['YEAR'] >= 2017) & (kenpom['YEAR'] <= 2023)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50c31128",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes['YEAR'] = resumes['YEAR'].astype(str)\n",
    "cbb['YEAR'] = cbb['YEAR'].astype(str)\n",
    "kenpom['YEAR'] = kenpom['YEAR'].astype(str)\n",
    "team_spellings['TeamID'] = team_spellings['TeamID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32b9e4dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corrections = {'illinois chicago':'1227',\n",
    "               'bethune cookman':'1126',\n",
    "               'maryland eastern shore':'1271',\n",
    "               'st. francis ny':'1383',\n",
    "               'st. francis pa':'1384',\n",
    "               'tennessee martin':'1404',\n",
    "               'louisiana monroe':'1419',\n",
    "               'ut rio grande valley':'1410',\n",
    "               'dixie st.':'1469',\n",
    "               'tarleton st.':'1470',\n",
    "               'st. thomas':'1472',\n",
    "               'texas a&m corpus chris':'1394',\n",
    "               'tamu-corpus christi':'1394',        \n",
    "               'louisiana lafayette':'1418',\n",
    "               'southeast missouri st.':'1369',\n",
    "               'cal st. bakersfield':'1167',\n",
    "               'cal state-bakersfield':'1167',\n",
    "               'arkansas pine bluff':'1115',\n",
    "               'mississippi valley st.':'1290',\n",
    "               \"st. mary's (ca)\":'1388',\n",
    "               'unc-wilmington':'1423',\n",
    "               'unc-greensboro':'1422',\n",
    "               'lasalle':'1247',\n",
    "               'tex. a&m-commerce':'1477',\n",
    "               'texas a&m commerce':'1477',\n",
    "               'lindenwood (mo)':'1473',\n",
    "               'cal state-northridge':'1169',\n",
    "               'houston christian':'1223',\n",
    "               'purdue-fort wayne':'1236',\n",
    "               'loyola (chicago)':'1260',\n",
    "               'md-eastern shore':'1271',\n",
    "               'uc-san diego':'1471',\n",
    "               'st. thomas (mn)':'1472',\n",
    "               'queens (nc)':'1474',\n",
    "               'queens':'1474',\n",
    "               'southern ind.':'1475'}\n",
    "\n",
    "for team,ID in corrections.items():\n",
    "    new_row = pd.DataFrame([[team, ID]], columns=['TeamNameSpelling', 'TeamID'])\n",
    "    team_spellings = pd.concat([team_spellings, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60e9f81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_16620\\3275743952.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  team_data['Team'] = team_data['Team'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n",
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_16620\\3275743952.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_data['Team'] = team_data['Team'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n"
     ]
    }
   ],
   "source": [
    "# create team data frame\n",
    "team_data = kpi[['Team', 'Year', 'KPI #', 'SOS']]\n",
    "\n",
    "# get team name into a format compatible with team_spellings data frame\n",
    "team_data['Team'] = team_data['Team'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n",
    "\n",
    "# add TeamID\n",
    "team_data = team_data.merge(team_spellings, left_on=['Team'], right_on=['TeamNameSpelling'], how='left')\n",
    "team_data.drop(['TeamNameSpelling'], axis=1, inplace=True)\n",
    "#team_data[team_data['TeamID'].isna()] # make sure all teams received a teamID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a043d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_16620\\2234263552.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  resumes['TEAM'] = resumes['TEAM'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>NET RPI</th>\n",
       "      <th>RESUME</th>\n",
       "      <th>WAB RANK</th>\n",
       "      <th>ELO</th>\n",
       "      <th>B POWER</th>\n",
       "      <th>Q1 W</th>\n",
       "      <th>Q1 PLUS Q2 W</th>\n",
       "      <th>Q3 Q4 L</th>\n",
       "      <th>R SCORE</th>\n",
       "      <th>TeamID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [YEAR, TEAM, NET RPI, RESUME, WAB RANK, ELO, B POWER, Q1 W, Q1 PLUS Q2 W, Q3 Q4 L, R SCORE, TeamID]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isolate relevant columns for remaining relevant data frames\n",
    "resumes = resumes[['YEAR','TEAM','NET RPI','RESUME','WAB RANK','ELO','B POWER', 'Q1 W', 'Q1 PLUS Q2 W', 'Q3 Q4 L', 'R SCORE']]\n",
    "\n",
    "# get team name into a format compatible with team_spellings data frame\n",
    "resumes['TEAM'] = resumes['TEAM'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n",
    "\n",
    "# add TeamID\n",
    "resumes = resumes.merge(team_spellings, left_on=['TEAM'], right_on=['TeamNameSpelling'], how='left')\n",
    "resumes.drop(['TeamNameSpelling'], axis=1, inplace=True)\n",
    "resumes[resumes['TeamID'].isna()] # make sure all teams received a teamID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2321989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add resume data\n",
    "team_data = team_data.merge(resumes, left_on=['TeamID','Year'], right_on=['TeamID','YEAR'], how='outer')\n",
    "team_data.drop(['TEAM', 'YEAR'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a81ddcb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_16620\\1733176395.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cbb['TEAM'] = cbb['TEAM'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>ADJOE</th>\n",
       "      <th>ADJDE</th>\n",
       "      <th>BARTHAG</th>\n",
       "      <th>EFG_O</th>\n",
       "      <th>EFG_D</th>\n",
       "      <th>TOR</th>\n",
       "      <th>TORD</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>FTR</th>\n",
       "      <th>FTRD</th>\n",
       "      <th>2P_O</th>\n",
       "      <th>2P_D</th>\n",
       "      <th>3P_O</th>\n",
       "      <th>3P_D</th>\n",
       "      <th>ADJ_T</th>\n",
       "      <th>WAB</th>\n",
       "      <th>TeamID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [YEAR, TEAM, ADJOE, ADJDE, BARTHAG, EFG_O, EFG_D, TOR, TORD, ORB, DRB, FTR, FTRD, 2P_O, 2P_D, 3P_O, 3P_D, ADJ_T, WAB, TeamID]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isolate relevant columns for remaining relevant data frames\n",
    "cbb = cbb[['YEAR', 'TEAM', 'ADJOE','ADJDE','BARTHAG','EFG_O','EFG_D','TOR','TORD', 'ORB', 'DRB', 'FTR', 'FTRD', \\\n",
    "           '2P_O', '2P_D', '3P_O', '3P_D', 'ADJ_T', 'WAB']]\n",
    "\n",
    "# get team name into a format compatible with team_spellings data frame\n",
    "cbb['TEAM'] = cbb['TEAM'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n",
    "\n",
    "# add TeamID\n",
    "cbb = cbb.merge(team_spellings, left_on=['TEAM'], right_on=['TeamNameSpelling'], how='left')\n",
    "cbb.drop(['TeamNameSpelling'], axis=1, inplace=True)\n",
    "cbb[cbb['TeamID'].isna()] # make sure all teams received a teamID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8deb7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cbb data\n",
    "team_data = team_data.merge(cbb, left_on=['TeamID','Year'], right_on=['TeamID','YEAR'], how='outer')\n",
    "team_data.drop(['TEAM', 'YEAR'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1124beb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_16620\\3773206749.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  kenpom['TEAM'] = kenpom['TEAM'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>QUAD ID</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>K TEMPO</th>\n",
       "      <th>KADJ T</th>\n",
       "      <th>K OFF</th>\n",
       "      <th>KADJ O</th>\n",
       "      <th>K DEF</th>\n",
       "      <th>KADJ D</th>\n",
       "      <th>KADJ EM</th>\n",
       "      <th>...</th>\n",
       "      <th>BADJ T</th>\n",
       "      <th>AVG HGT</th>\n",
       "      <th>EFF HGT</th>\n",
       "      <th>EXP</th>\n",
       "      <th>TALENT</th>\n",
       "      <th>FT%</th>\n",
       "      <th>PPPO</th>\n",
       "      <th>PPPD</th>\n",
       "      <th>ELITE SOS</th>\n",
       "      <th>TeamID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [YEAR, QUAD ID, TEAM, K TEMPO, KADJ T, K OFF, KADJ O, K DEF, KADJ D, KADJ EM, BADJ EM, BADJ O, BADJ D, EFG%, TOV%, TOV%D, OREB%, DREB%, OP OREB%, OP DREB%, BLK%, BLKED%, AST%, OP AST%, BADJ T, AVG HGT, EFF HGT, EXP, TALENT, FT%, PPPO, PPPD, ELITE SOS, TeamID]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 34 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isolate relevant columns for remaining relevant data frames\n",
    "kenpom = kenpom[['YEAR','QUAD ID','TEAM','K TEMPO','KADJ T','K OFF','KADJ O','K DEF','KADJ D','KADJ EM','BADJ EM', \\\n",
    "                'BADJ O','BADJ D','EFG%','TOV%','TOV%D','OREB%','DREB%','OP OREB%','OP DREB%','BLK%','BLKED%', \\\n",
    "                'AST%','OP AST%','BADJ T','AVG HGT','EFF HGT','EXP','TALENT','FT%', 'PPPO', 'PPPD','ELITE SOS']]\n",
    "\n",
    "# get team name into a format compatible with team_spellings data frame\n",
    "kenpom['TEAM'] = kenpom['TEAM'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n",
    "\n",
    "# add TeamID\n",
    "kenpom = kenpom.merge(team_spellings, left_on=['TEAM'], right_on=['TeamNameSpelling'], how='left')\n",
    "kenpom.drop(['TeamNameSpelling'], axis=1, inplace=True)\n",
    "kenpom[kenpom['TeamID'].isna()] # make sure all teams received a teamID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44af4ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cbb data\n",
    "team_data = team_data.merge(kenpom, left_on=['TeamID','Year'], right_on=['TeamID','YEAR'], how='outer')\n",
    "team_data.drop(['TEAM', 'YEAR'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc0041",
   "metadata": {},
   "source": [
    "# Repeat Process for 2024 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9d6141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_16620\\2035469998.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  team_data24['Team'] = team_data24['Team'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n",
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_16620\\2035469998.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_data24['Team'] = team_data24['Team'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>KPI #</th>\n",
       "      <th>SOS</th>\n",
       "      <th>TeamID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>non d-i</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.009</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Team  KPI #    SOS TeamID\n",
       "359  non d-i  -0.37  0.009    NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create team data frame\n",
    "team_data24 = kpi24[['Team', 'KPI #', 'SOS']]\n",
    "\n",
    "# get team name into a format compatible with team_spellings data frame\n",
    "team_data24['Team'] = team_data24['Team'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n",
    "\n",
    "# add TeamID\n",
    "team_data24 = team_data24.merge(team_spellings, left_on=['Team'], right_on=['TeamNameSpelling'], how='left')\n",
    "team_data24.drop(['TeamNameSpelling'], axis=1, inplace=True)\n",
    "team_data24[team_data24['TeamID'].isna()] # make sure all teams received a teamID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53368dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_16620\\1594971604.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  resumes24['TEAM'] = resumes24['TEAM'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM</th>\n",
       "      <th>NET RPI</th>\n",
       "      <th>RESUME</th>\n",
       "      <th>WAB RANK</th>\n",
       "      <th>ELO</th>\n",
       "      <th>B POWER</th>\n",
       "      <th>Q1 W</th>\n",
       "      <th>Q1 PLUS Q2 W</th>\n",
       "      <th>Q3 Q4 L</th>\n",
       "      <th>R SCORE</th>\n",
       "      <th>TeamID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TEAM, NET RPI, RESUME, WAB RANK, ELO, B POWER, Q1 W, Q1 PLUS Q2 W, Q3 Q4 L, R SCORE, TeamID]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isolate relevant columns for remaining relevant data frames\n",
    "resumes24 = resumes24[['TEAM','NET RPI','RESUME','WAB RANK','ELO','B POWER', 'Q1 W', 'Q1 PLUS Q2 W', 'Q3 Q4 L', 'R SCORE']]\n",
    "\n",
    "# get team name into a format compatible with team_spellings data frame\n",
    "resumes24['TEAM'] = resumes24['TEAM'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n",
    "\n",
    "# add TeamID\n",
    "resumes24 = resumes24.merge(team_spellings, left_on=['TEAM'], right_on=['TeamNameSpelling'], how='left')\n",
    "resumes24.drop(['TeamNameSpelling'], axis=1, inplace=True)\n",
    "resumes24[resumes24['TeamID'].isna()] # make sure all teams received a teamID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc0624d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add resume data\n",
    "team_data24 = team_data24.merge(resumes24, left_on=['TeamID'], right_on=['TeamID'], how='outer')\n",
    "team_data24.drop(['TEAM'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0463c65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_16620\\43191826.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cbb24['TEAM'] = cbb24['TEAM'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM</th>\n",
       "      <th>ADJOE</th>\n",
       "      <th>ADJDE</th>\n",
       "      <th>BARTHAG</th>\n",
       "      <th>EFG_O</th>\n",
       "      <th>EFG_D</th>\n",
       "      <th>TOR</th>\n",
       "      <th>TORD</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>FTR</th>\n",
       "      <th>FTRD</th>\n",
       "      <th>2P_O</th>\n",
       "      <th>2P_D</th>\n",
       "      <th>3P_O</th>\n",
       "      <th>3P_D</th>\n",
       "      <th>ADJ_T</th>\n",
       "      <th>WAB</th>\n",
       "      <th>TeamID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TEAM, ADJOE, ADJDE, BARTHAG, EFG_O, EFG_D, TOR, TORD, ORB, DRB, FTR, FTRD, 2P_O, 2P_D, 3P_O, 3P_D, ADJ_T, WAB, TeamID]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isolate relevant columns for remaining relevant data frames\n",
    "cbb24.rename(columns={'EFG%': 'EFG_O', 'EFGD%': 'EFG_D'}, inplace=True)\n",
    "cbb24 = cbb24[['TEAM', 'ADJOE','ADJDE','BARTHAG','EFG_O','EFG_D','TOR','TORD', 'ORB', 'DRB', 'FTR', 'FTRD', \\\n",
    "               '2P_O', '2P_D', '3P_O', '3P_D', 'ADJ_T', 'WAB']]\n",
    "\n",
    "# get team name into a format compatible with team_spellings data frame\n",
    "cbb24['TEAM'] = cbb24['TEAM'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n",
    "\n",
    "# add TeamID\n",
    "cbb24 = cbb24.merge(team_spellings, left_on=['TEAM'], right_on=['TeamNameSpelling'], how='left')\n",
    "cbb24.drop(['TeamNameSpelling'], axis=1, inplace=True)\n",
    "cbb24[cbb24['TeamID'].isna()] # make sure all teams received a teamID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19c10d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cbb data\n",
    "team_data24 = team_data24.merge(cbb24, left_on=['TeamID'], right_on=['TeamID'], how='outer')\n",
    "team_data24.drop(['TEAM'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2b01c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_16620\\4168628599.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  kenpom24['TEAM'] = kenpom24['TEAM'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUAD ID</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>K TEMPO</th>\n",
       "      <th>KADJ T</th>\n",
       "      <th>K OFF</th>\n",
       "      <th>KADJ O</th>\n",
       "      <th>K DEF</th>\n",
       "      <th>KADJ D</th>\n",
       "      <th>KADJ EM</th>\n",
       "      <th>BADJ EM</th>\n",
       "      <th>...</th>\n",
       "      <th>BADJ T</th>\n",
       "      <th>AVG HGT</th>\n",
       "      <th>EFF HGT</th>\n",
       "      <th>EXP</th>\n",
       "      <th>TALENT</th>\n",
       "      <th>FT%</th>\n",
       "      <th>PPPO</th>\n",
       "      <th>PPPD</th>\n",
       "      <th>ELITE SOS</th>\n",
       "      <th>TeamID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [QUAD ID, TEAM, K TEMPO, KADJ T, K OFF, KADJ O, K DEF, KADJ D, KADJ EM, BADJ EM, BADJ O, BADJ D, EFG%, TOV%, TOV%D, OREB%, DREB%, OP OREB%, OP DREB%, BLK%, BLKED%, AST%, OP AST%, BADJ T, AVG HGT, EFF HGT, EXP, TALENT, FT%, PPPO, PPPD, ELITE SOS, TeamID]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 33 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isolate relevant columns for remaining relevant data frames\n",
    "kenpom24 = kenpom24[['QUAD ID','TEAM','K TEMPO','KADJ T','K OFF','KADJ O','K DEF','KADJ D','KADJ EM','BADJ EM', \\\n",
    "                     'BADJ O','BADJ D','EFG%','TOV%','TOV%D','OREB%','DREB%','OP OREB%','OP DREB%','BLK%','BLKED%', \\\n",
    "                     'AST%','OP AST%','BADJ T','AVG HGT','EFF HGT','EXP','TALENT','FT%', 'PPPO', 'PPPD','ELITE SOS']]\n",
    "\n",
    "# get team name into a format compatible with team_spellings data frame\n",
    "kenpom24['TEAM'] = kenpom24['TEAM'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n",
    "\n",
    "# add TeamID\n",
    "kenpom24 = kenpom24.merge(team_spellings, left_on=['TEAM'], right_on=['TeamNameSpelling'], how='left')\n",
    "kenpom24.drop(['TeamNameSpelling'], axis=1, inplace=True)\n",
    "kenpom24[kenpom24['TeamID'].isna()] # make sure all teams received a teamID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d898a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cbb data\n",
    "team_data24 = team_data24.merge(kenpom24, left_on=['TeamID'], right_on=['TeamID'], how='outer')\n",
    "team_data24.drop(['TEAM'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a50903",
   "metadata": {},
   "source": [
    "# Add Team Stats Back to Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d01a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_results['Season'] = mm_results['Season'].astype(str)\n",
    "mm_results['ATeamID'] = mm_results['ATeamID'].astype(str)\n",
    "mm_results['BTeamID'] = mm_results['BTeamID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ac9bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winner(row):\n",
    "    if row['AScore'] > row['BScore']:\n",
    "        return True\n",
    "    elif row['BScore'] > row['AScore']:\n",
    "        return False\n",
    "\n",
    "mm_results['AWon'] = mm_results.apply(winner, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8c8d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_results = mm_results.merge(team_data, left_on=['ATeamID','Season'], right_on=['TeamID','Year'], how='left')\n",
    "mm_results = mm_results.merge(team_data, left_on=['BTeamID','Season'], right_on=['TeamID','Year'], how='left', suffixes=('_A', '_B'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4333a6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure there are zero NA values in the final data set for training the neural network\n",
    "mm_results.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "694a47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = mm_results.drop(['DayNum','Round','AScore','BScore','ATeamID','BTeamID','Team_A','Team_B', \\\n",
    "                               'Year_A','Year_B','TeamID_A','TeamID_B'], axis=1)\n",
    "\n",
    "# make everything except for 'Winner' a float\n",
    "for col in training_df.columns:\n",
    "    if col not in ['Season','ATeamName','BTeamName','AWon']:\n",
    "        training_df[col] = training_df[col].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45ff899",
   "metadata": {},
   "source": [
    "# Build Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0eb209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ethan\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4316b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upset_weights(row):\n",
    "    if ((row['ASeed'] >= row['BSeed'] + 2) & (row['AWon'] == True) or \\\n",
    "        (row['BSeed'] >= row['ASeed'] + 2) & (row['AWon'] == False)):\n",
    "        return 293/88\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "training_df['Upset'] = training_df.apply(upset_weights, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7146e87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = pd.DataFrame(MinMaxScaler(). \\\n",
    "                         fit_transform(training_df.drop(columns=['Season','ATeamName','BTeamName','AWon','Upset'])), \\\n",
    "                         columns=training_df.drop(columns=['Season','ATeamName','BTeamName','AWon','Upset']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a3426a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df['AWon'] = training_df['AWon']\n",
    "scaled_df['Upset'] = training_df['Upset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a26d7762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set appropriate x and y values\n",
    "x = scaled_df.drop(columns=['AWon','Upset'])\n",
    "y = scaled_df.AWon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef6e4fb",
   "metadata": {},
   "source": [
    "Feature selection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e24ba37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use random forest technique for feature importance\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(x,y)\n",
    "rf_imps = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69625028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gradient boosting technique for feature importance\n",
    "xg_reg = xgb.XGBRegressor()\n",
    "xg_reg.fit(x,y)\n",
    "xg_imps = xg_reg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "796a25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine these techniques into a dataframe\n",
    "importance = pd.DataFrame({'Feature':x.columns, 'Random Forest':rf_imps, 'Gradient Boosting':xg_imps})\n",
    "\n",
    "# average feature importance for two teams\n",
    "importance['Feature'] = importance['Feature'].apply(lambda x: x[:-2])\n",
    "importance.loc['ASeed', 'Feature'] = 'Seed_A'\n",
    "importance.loc['BSeed', 'Feature'] = 'Seed_B'\n",
    "rf_pivot = pd.pivot_table(importance, index='Feature', columns=None, values='Random Forest', aggfunc='mean')\n",
    "xg_pivot = pd.pivot_table(importance, index='Feature', columns=None, values='Gradient Boosting', aggfunc='mean')\n",
    "importance = rf_pivot.merge(xg_pivot, on = 'Feature')\n",
    "\n",
    "# filter for the most important features\n",
    "rf_mask = (importance['Random Forest'] >= importance['Random Forest'].median())\n",
    "gb_mask = (importance['Gradient Boosting'] >= importance['Gradient Boosting'].median())\n",
    "importance = importance[rf_mask & gb_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29cdd47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_columns = [column for column in training_df.columns if any(name in column for name in importance.index)]\n",
    "x = scaled_df[imp_columns]\n",
    "y = scaled_df.AWon\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.33,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e97bacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ethan\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build neural network model\n",
    "NNmodel = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32,activation='relu',input_shape=(len(x.columns),)),\n",
    "    tf.keras.layers.Dense(16,activation='relu'),\n",
    "    tf.keras.layers.Dense(8,activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation=tf.nn.sigmoid)])\n",
    "\n",
    "NNmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              weighted_metrics=[]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e89bab87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df = xtrain.merge(scaled_df, left_index=True, right_index=True)\n",
    "xtrain['Upset'] = merged_df['Upset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0dacb5a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\ethan\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ethan\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "17/17 [==============================] - 2s 20ms/step - loss: 1.1038 - accuracy: 0.5235 - val_loss: 1.0384 - val_accuracy: 0.5294\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.0539 - accuracy: 0.5235 - val_loss: 1.0719 - val_accuracy: 0.4824\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.0380 - accuracy: 0.5176 - val_loss: 1.0573 - val_accuracy: 0.4824\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0296 - accuracy: 0.5176 - val_loss: 1.0517 - val_accuracy: 0.4824\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1.0375 - accuracy: 0.5176 - val_loss: 1.0683 - val_accuracy: 0.4824\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0271 - accuracy: 0.6059 - val_loss: 1.0472 - val_accuracy: 0.7059\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0234 - accuracy: 0.7000 - val_loss: 1.0951 - val_accuracy: 0.5647\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.0226 - accuracy: 0.5176 - val_loss: 1.0958 - val_accuracy: 0.5059\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.0195 - accuracy: 0.5706 - val_loss: 1.1004 - val_accuracy: 0.5647\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.0170 - accuracy: 0.5941 - val_loss: 1.0837 - val_accuracy: 0.7176\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.0206 - accuracy: 0.6059 - val_loss: 1.0553 - val_accuracy: 0.6588\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0101 - accuracy: 0.7059 - val_loss: 1.0977 - val_accuracy: 0.4941\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0031 - accuracy: 0.5471 - val_loss: 1.1213 - val_accuracy: 0.5412\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.9921 - accuracy: 0.7118 - val_loss: 1.1257 - val_accuracy: 0.5529\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0073 - accuracy: 0.6294 - val_loss: 1.0669 - val_accuracy: 0.6706\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.9784 - accuracy: 0.6647 - val_loss: 1.0985 - val_accuracy: 0.6000\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9835 - accuracy: 0.6706 - val_loss: 1.1869 - val_accuracy: 0.5176\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9560 - accuracy: 0.6765 - val_loss: 1.0994 - val_accuracy: 0.7176\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9400 - accuracy: 0.7353 - val_loss: 1.1647 - val_accuracy: 0.5412\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9438 - accuracy: 0.6941 - val_loss: 1.0777 - val_accuracy: 0.7059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19fc5677eb0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "NNmodel.fit(xtrain.drop(columns='Upset'), \\\n",
    "            ytrain, epochs=20, batch_size=10, validation_split=0.33, \\\n",
    "            sample_weight=xtrain['Upset']\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09560c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.5556\n",
      "This model predicts 55.5556% of the test data correctly\n"
     ]
    }
   ],
   "source": [
    "# evaluate model testing accuracy\n",
    "print('This model predicts '+str(round(NNmodel.evaluate(xtest,ytest)[1]*100,4)) +'% of the test data correctly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ad598e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>ATeamName</th>\n",
       "      <th>BTeamName</th>\n",
       "      <th>ASeed</th>\n",
       "      <th>BSeed</th>\n",
       "      <th>AWon</th>\n",
       "      <th>KPI #_A</th>\n",
       "      <th>SOS_A</th>\n",
       "      <th>NET RPI_A</th>\n",
       "      <th>RESUME_A</th>\n",
       "      <th>...</th>\n",
       "      <th>AVG HGT_B</th>\n",
       "      <th>EFF HGT_B</th>\n",
       "      <th>EXP_B</th>\n",
       "      <th>TALENT_B</th>\n",
       "      <th>FT%_B</th>\n",
       "      <th>PPPO_B</th>\n",
       "      <th>PPPD_B</th>\n",
       "      <th>ELITE SOS_B</th>\n",
       "      <th>Upset</th>\n",
       "      <th>AProb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>2023</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>TAM C. Christi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.198</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.074</td>\n",
       "      <td>78.271</td>\n",
       "      <td>2.721</td>\n",
       "      <td>3.833</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.098</td>\n",
       "      <td>1.023</td>\n",
       "      <td>9.546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>2023</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>Houston</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.185</td>\n",
       "      <td>32.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.743</td>\n",
       "      <td>79.511</td>\n",
       "      <td>1.611</td>\n",
       "      <td>68.424</td>\n",
       "      <td>71.9</td>\n",
       "      <td>1.158</td>\n",
       "      <td>0.872</td>\n",
       "      <td>23.376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.664826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2021</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Loyola-Chicago</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.148</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.146</td>\n",
       "      <td>79.589</td>\n",
       "      <td>2.231</td>\n",
       "      <td>11.054</td>\n",
       "      <td>73.3</td>\n",
       "      <td>1.102</td>\n",
       "      <td>0.873</td>\n",
       "      <td>16.033</td>\n",
       "      <td>3.329545</td>\n",
       "      <td>0.664141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2019</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Ohio St</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.090</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.691</td>\n",
       "      <td>79.478</td>\n",
       "      <td>1.460</td>\n",
       "      <td>56.419</td>\n",
       "      <td>73.4</td>\n",
       "      <td>1.037</td>\n",
       "      <td>0.986</td>\n",
       "      <td>33.733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.663094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2023</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>San Diego St</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.100</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.704</td>\n",
       "      <td>80.193</td>\n",
       "      <td>2.718</td>\n",
       "      <td>37.236</td>\n",
       "      <td>73.6</td>\n",
       "      <td>1.064</td>\n",
       "      <td>0.952</td>\n",
       "      <td>25.602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.661831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>Mt St Mary's</td>\n",
       "      <td>Villanova</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>150.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.636</td>\n",
       "      <td>79.413</td>\n",
       "      <td>1.845</td>\n",
       "      <td>75.837</td>\n",
       "      <td>79.4</td>\n",
       "      <td>1.180</td>\n",
       "      <td>0.954</td>\n",
       "      <td>30.578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2019</td>\n",
       "      <td>Iona</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>202.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.502</td>\n",
       "      <td>80.814</td>\n",
       "      <td>1.759</td>\n",
       "      <td>76.654</td>\n",
       "      <td>74.2</td>\n",
       "      <td>1.126</td>\n",
       "      <td>0.955</td>\n",
       "      <td>36.978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2019</td>\n",
       "      <td>F Dickinson</td>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>203.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.212</td>\n",
       "      <td>80.475</td>\n",
       "      <td>1.839</td>\n",
       "      <td>55.473</td>\n",
       "      <td>76.7</td>\n",
       "      <td>1.241</td>\n",
       "      <td>0.909</td>\n",
       "      <td>21.704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2018</td>\n",
       "      <td>TX Southern</td>\n",
       "      <td>Xavier</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>222.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.483</td>\n",
       "      <td>80.776</td>\n",
       "      <td>1.844</td>\n",
       "      <td>76.280</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.155</td>\n",
       "      <td>1.021</td>\n",
       "      <td>31.853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.073880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2023</td>\n",
       "      <td>F Dickinson</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>301.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.560</td>\n",
       "      <td>83.422</td>\n",
       "      <td>1.238</td>\n",
       "      <td>58.603</td>\n",
       "      <td>74.3</td>\n",
       "      <td>1.135</td>\n",
       "      <td>0.974</td>\n",
       "      <td>31.016</td>\n",
       "      <td>3.329545</td>\n",
       "      <td>0.057580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>381 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season     ATeamName       BTeamName  ASeed  BSeed   AWon  KPI #_A  SOS_A  \\\n",
       "318   2023       Alabama  TAM C. Christi    1.0   16.0   True    0.489  0.198   \n",
       "352   2023        Auburn         Houston    9.0    1.0  False    0.259  0.185   \n",
       "227   2021      Illinois  Loyola-Chicago    1.0    8.0  False    0.329  0.148   \n",
       "167   2019       Houston         Ohio St    3.0   11.0   True    0.401  0.090   \n",
       "380   2023   Connecticut    San Diego St    4.0    5.0   True    0.287  0.100   \n",
       "..     ...           ...             ...    ...    ...    ...      ...    ...   \n",
       "11    2017  Mt St Mary's       Villanova   16.0    1.0  False   -0.019 -0.061   \n",
       "147   2019          Iona  North Carolina   16.0    1.0  False   -0.087 -0.120   \n",
       "130   2019   F Dickinson         Gonzaga   16.0    1.0  False   -0.065 -0.152   \n",
       "94    2018   TX Southern          Xavier   16.0    1.0  False   -0.102 -0.066   \n",
       "337   2023   F Dickinson          Purdue   16.0    1.0   True   -0.159 -0.210   \n",
       "\n",
       "     NET RPI_A  RESUME_A  ...  AVG HGT_B  EFF HGT_B  EXP_B  TALENT_B  FT%_B  \\\n",
       "318        2.0       3.0  ...     75.074     78.271  2.721     3.833   80.0   \n",
       "352       32.0      49.0  ...     76.743     79.511  1.611    68.424   71.9   \n",
       "227        3.0       1.0  ...     76.146     79.589  2.231    11.054   73.3   \n",
       "167        4.0      16.0  ...     76.691     79.478  1.460    56.419   73.4   \n",
       "380        8.0      19.0  ...     76.704     80.193  2.718    37.236   73.6   \n",
       "..         ...       ...  ...        ...        ...    ...       ...    ...   \n",
       "11       150.0     218.0  ...     77.636     79.413  1.845    75.837   79.4   \n",
       "147      202.0     273.0  ...     78.502     80.814  1.759    76.654   74.2   \n",
       "130      203.0     263.0  ...     78.212     80.475  1.839    55.473   76.7   \n",
       "94       222.0     245.0  ...     78.483     80.776  1.844    76.280   79.0   \n",
       "337      301.0     329.0  ...     78.560     83.422  1.238    58.603   74.3   \n",
       "\n",
       "     PPPO_B  PPPD_B  ELITE SOS_B     Upset     AProb  \n",
       "318   1.098   1.023        9.546  1.000000  0.666133  \n",
       "352   1.158   0.872       23.376  1.000000  0.664826  \n",
       "227   1.102   0.873       16.033  3.329545  0.664141  \n",
       "167   1.037   0.986       33.733  1.000000  0.663094  \n",
       "380   1.064   0.952       25.602  1.000000  0.661831  \n",
       "..      ...     ...          ...       ...       ...  \n",
       "11    1.180   0.954       30.578  1.000000  0.109585  \n",
       "147   1.126   0.955       36.978  1.000000  0.094353  \n",
       "130   1.241   0.909       21.704  1.000000  0.091899  \n",
       "94    1.155   1.021       31.853  1.000000  0.073880  \n",
       "337   1.135   0.974       31.016  3.329545  0.057580  \n",
       "\n",
       "[381 rows x 126 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the games where team A is most and least likely to win\n",
    "training_df['AProb'] = NNmodel.predict(x)\n",
    "training_df[(training_df['ASeed'].isin([5.0,12.0])) & (training_df['BSeed'].isin([5.0,12.0]))].sort_values(by='AProb', ascending=False)\n",
    "training_df.sort_values(by='AProb', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd9d0ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SOS_A',\n",
       " 'NET RPI_A',\n",
       " 'RESUME_A',\n",
       " 'WAB RANK_A',\n",
       " 'B POWER_A',\n",
       " 'R SCORE_A',\n",
       " 'ADJOE_A',\n",
       " 'ADJDE_A',\n",
       " 'BARTHAG_A',\n",
       " 'FTRD_A',\n",
       " '3P_D_A',\n",
       " 'KADJ O_A',\n",
       " 'BADJ EM_A',\n",
       " 'BADJ O_A',\n",
       " 'AVG HGT_A',\n",
       " 'EFF HGT_A',\n",
       " 'FT%_A',\n",
       " 'ELITE SOS_A',\n",
       " 'SOS_B',\n",
       " 'NET RPI_B',\n",
       " 'RESUME_B',\n",
       " 'WAB RANK_B',\n",
       " 'B POWER_B',\n",
       " 'R SCORE_B',\n",
       " 'ADJOE_B',\n",
       " 'ADJDE_B',\n",
       " 'BARTHAG_B',\n",
       " 'FTRD_B',\n",
       " '3P_D_B',\n",
       " 'KADJ O_B',\n",
       " 'BADJ EM_B',\n",
       " 'BADJ O_B',\n",
       " 'AVG HGT_B',\n",
       " 'EFF HGT_B',\n",
       " 'FT%_B',\n",
       " 'ELITE SOS_B']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e5a4a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AProb</th>\n",
       "      <th>Important</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WAB</th>\n",
       "      <td>0.541700</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADJ EM</th>\n",
       "      <td>0.532291</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KADJ EM</th>\n",
       "      <td>0.525229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KPI #</th>\n",
       "      <td>0.521994</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seed</th>\n",
       "      <td>0.516072</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADJ O</th>\n",
       "      <td>0.511579</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KADJ O</th>\n",
       "      <td>0.509522</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJOE</th>\n",
       "      <td>0.504469</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BARTHAG</th>\n",
       "      <td>0.496777</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAB RANK</th>\n",
       "      <td>0.496753</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AProb Important\n",
       "Feature                     \n",
       "WAB       0.541700     False\n",
       "BADJ EM   0.532291      True\n",
       "KADJ EM   0.525229     False\n",
       "KPI #     0.521994     False\n",
       "Seed      0.516072     False\n",
       "BADJ O    0.511579      True\n",
       "KADJ O    0.509522      True\n",
       "ADJOE     0.504469      True\n",
       "BARTHAG   0.496777      True\n",
       "WAB RANK  0.496753      True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print model variables that most strongly correlate with probability of winning\n",
    "corrs = pd.DataFrame({'Feature':training_df.drop(columns=['Season','ATeamName','BTeamName']).columns,\n",
    "                      'AProb':training_df.corr()['AProb']})\n",
    "\n",
    "corrs.drop(['AWon','AProb'], inplace=True)\n",
    "corrs.loc['ASeed', 'Feature'] = 'Seed_A'\n",
    "corrs.loc['BSeed', 'Feature'] = 'Seed_B'\n",
    "\n",
    "corrs['Feature'] = corrs['Feature'].apply(lambda x: x[:-2])\n",
    "pivot = pd.pivot_table(corrs, index='Feature', columns=None, values='AProb', aggfunc=lambda x: abs(x).mean())\n",
    "\n",
    "def imp(feature):\n",
    "    if feature + '_A' in imp_columns:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "pivot['Important'] = pivot.index.map(imp)\n",
    "pivot.sort_values(by='AProb', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583fb9c9",
   "metadata": {},
   "source": [
    "# Apply Model to 2024 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups = pd.read_excel('MM_matchups24.xlsx')\n",
    "\n",
    "def rename_teams(row):\n",
    "    sorted_names = sorted([row['HTeamName'], row['LTeamName']])\n",
    "    return pd.Series({'ATeamName': sorted_names[0], 'BTeamName': sorted_names[1]})\n",
    "\n",
    "new_columns = matchups.apply(rename_teams, axis=1)\n",
    "matchups = pd.concat([matchups, new_columns], axis=1)\n",
    "\n",
    "def match_team_info(row):\n",
    "    if row['HTeamName'] == row['ATeamName']:\n",
    "        return pd.Series({'ASeed': row['HSeed'], 'BSeed': row['LSeed']})\n",
    "    elif row['HTeamName'] == row['BTeamName']:\n",
    "        return pd.Series({'BSeed': row['HSeed'], 'ASeed': row['LSeed']})\n",
    "\n",
    "new_columns = matchups.apply(match_team_info, axis=1)\n",
    "matchups = pd.concat([matchups, new_columns], axis=1)\n",
    "matchups.drop(['HTeamName','LTeamName','HSeed','LSeed'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda01a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups['ATeamName'] = matchups['ATeamName'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: x.lower())\n",
    "matchups['BTeamName'] = matchups['BTeamName'].str.replace(r'\\bSt\\.\\b', 'State').apply(lambda x: str(x).lower())\n",
    "\n",
    "# add TeamID\n",
    "matchups = matchups.merge(team_spellings, left_on=['ATeamName'], right_on=['TeamNameSpelling'], how='left')\n",
    "matchups.drop(['TeamNameSpelling'], axis=1, inplace=True)\n",
    "\n",
    "matchups = matchups.merge(team_spellings, left_on=['BTeamName'], right_on=['TeamNameSpelling'], how='left')\n",
    "matchups.drop(['TeamNameSpelling'], axis=1, inplace=True)\n",
    "\n",
    "matchups.rename(columns={'TeamID_x': 'ATeamID', 'TeamID_y': 'BTeamID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups = matchups.merge(team_data24, left_on=['ATeamID'], right_on=['TeamID'], how='left')\n",
    "matchups = matchups.merge(team_data24, left_on=['BTeamID'], right_on=['TeamID'], how='left', suffixes=('_A', '_B'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = matchups.drop(['Region','Round','ATeamID','BTeamID','Team_A','Team_B','TeamID_A','TeamID_B'], axis=1)\n",
    "\n",
    "# make everything except for 'Winner' a float\n",
    "for col in testing_df.columns:\n",
    "    if col not in ['ATeamName','BTeamName']:\n",
    "        testing_df[col] = testing_df[col].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14950ef2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaled_test_df = pd.DataFrame(MinMaxScaler(). \\\n",
    "                              fit_transform(testing_df.drop(columns=['ATeamName','BTeamName'])), \\\n",
    "                              columns=testing_df.drop(columns=['ATeamName','BTeamName']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0847824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x24 = scaled_test_df[imp_columns]\n",
    "testing_df['AProb'] = NNmodel.predict(x24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4286f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = testing_df[['ATeamName','BTeamName','ASeed','BSeed','AProb']]\n",
    "\n",
    "def order_seeds(row):\n",
    "    if row['ASeed'] > row['BSeed']:\n",
    "        return pd.Series({'HTeamName': row['BTeamName'], 'LTeamName': row['ATeamName'],\n",
    "                          'HSeed': row['BSeed'], 'LSeed': row['ASeed'],\n",
    "                          'HProb': 1 - row['AProb'], 'LProb': row['AProb']})\n",
    "    else:\n",
    "        return pd.Series({'HTeamName': row['ATeamName'], 'LTeamName': row['BTeamName'],\n",
    "                          'HSeed': row['ASeed'], 'LSeed': row['BSeed'],\n",
    "                          'HProb': row['AProb'], 'LProb': 1 - row['AProb']})\n",
    "\n",
    "new_columns = testing_df.apply(order_seeds, axis=1)\n",
    "testing_df = pd.concat([testing_df, new_columns], axis=1)\n",
    "testing_df.drop(columns=['ATeamName','BTeamName','ASeed','BSeed','AProb'], inplace=True)\n",
    "\n",
    "matchup_merger = matchups[['Round','ATeamName','BTeamName']]\n",
    "new_columns = testing_df.apply(rename_teams, axis=1)\n",
    "testing_df = pd.concat([testing_df, new_columns], axis=1)\n",
    "\n",
    "testing_df = testing_df.merge(matchup_merger, on=['ATeamName','BTeamName'])\n",
    "testing_df.drop(columns=['ATeamName','BTeamName'], inplace=True)\n",
    "testing_df.sort_values(by='LProb', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f247de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob24_results = {}\n",
    "for index, row in testing_df.iterrows():\n",
    "    key = row['HTeamName']\n",
    "    value = row['HProb']\n",
    "    if key in prob24_results:\n",
    "        prob24_results[key].append(value)\n",
    "    else:\n",
    "        prob24_results[key] = [value]\n",
    "prob24_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb37a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an upset is defined as a team at least two seeds worse winning (i.e. 10 vs 7 but not 9 vs 8)\n",
    "print('First round upsets:', round(upsets['FIRST ROUND'].mean(),1))\n",
    "print('Second round upsets:', round(upsets['SECOND ROUND'].mean(),1))\n",
    "print('Sweet 16 upsets:', round(upsets['SWEET 16'].mean(),1))\n",
    "print('Elite 8 upsets:', round(upsets['ELITE 8'].mean(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to ESPN analytics\n",
    "\n",
    "# Michigan State 57.7%\n",
    "# BYU 81.7%\n",
    "# Creighton 90.6%\n",
    "# Arizona 97.8%\n",
    "# North Carolina 98.8%\n",
    "# Illinois 89.0%\n",
    "# South Carolina 55.6%\n",
    "# Dayton 57.3%\n",
    "# Texas 71.9%\n",
    "# Kentucky 90.4%\n",
    "# Iowa State 96.7%\n",
    "# Gonzaga 76.6%\n",
    "# Tennessee 98.1%\n",
    "# Texas Tech 61.3%\n",
    "# Washington State 51.2%\n",
    "# Kansas 83.7%\n",
    "# Florida Atlantic 54.8%\n",
    "# Baylor 90.6%\n",
    "# San Diego State 85.0%\n",
    "# Marquette 94.1%\n",
    "# Clemson 57.8%\n",
    "# UConn 98.7%\n",
    "# Auburn 90.5%\n",
    "# Florida 63.2%\n",
    "# Texas A&M 52.6%\n",
    "# Duke 88.3%\n",
    "# Purdue 99.5%\n",
    "# Alabama 90.4%\n",
    "# Houston 98.6%\n",
    "# Wisconsin 68.6%\n",
    "# TCU 72.5%\n",
    "# Saint Mary's 78.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df07f47e",
   "metadata": {},
   "source": [
    "# Experiment in Using Gurobi to Optimize Neural Network - Not Deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cbfdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_model(params):\n",
    "    layers = int(params[0])\n",
    "    nodes = int(params[1])\n",
    "    dropout = params[2]\n",
    "    #epochs = int(params[3])\n",
    "    #batch_size = int(params[4])\n",
    "    #val_split = params[5]\n",
    "    \n",
    "    accuracies = []\n",
    "    for i in range(3):\n",
    "        scaled_df = pd.DataFrame(MinMaxScaler(). \\\n",
    "                         fit_transform(training_df.drop(columns=['Season','ATeamName','BTeamName','AWon'])), \\\n",
    "                         columns=training_df.drop(columns=['Season','ATeamName','BTeamName','AWon']).columns)\n",
    "        \n",
    "        scaled_df['AWon'] = training_df['AWon']\n",
    "        \n",
    "        x = scaled_df.drop(columns='AWon')\n",
    "        y = scaled_df.AWon\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.33,random_state=3)\n",
    "    \n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(x,y)\n",
    "        rf_imps = rf.feature_importances_\n",
    "\n",
    "        xg_reg = xgb.XGBRegressor()\n",
    "        xg_reg.fit(x,y)\n",
    "        xg_imps = xg_reg.feature_importances_\n",
    "\n",
    "        importance = pd.DataFrame({'Feature':x.columns, 'Random Forest':rf_imps, 'Gradient Boosting':xg_imps})\n",
    "        importance['Feature'] = importance['Feature'].apply(lambda x: x[:-2])\n",
    "        rf_pivot = pd.pivot_table(importance, index='Feature', columns=None, values='Random Forest', aggfunc='mean')\n",
    "        xg_pivot = pd.pivot_table(importance, index='Feature', columns=None, values='Gradient Boosting', aggfunc='mean')\n",
    "        importance = rf_pivot.merge(xg_pivot, on = 'Feature')\n",
    "        importance = importance[(importance['Random Forest'] >= 0.007) & (importance['Gradient Boosting'] >= 0.007)]\n",
    "\n",
    "        imp_columns = [column for column in training_df.columns if any(name in column for name in importance.index)]\n",
    "        x = scaled_df[imp_columns]\n",
    "        y = scaled_df.AWon\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.33,random_state=3)\n",
    "        \n",
    "        sequential = []\n",
    "        sequential.append(tf.keras.layers.Dense(nodes, activation='relu', input_shape=(len(x.columns),)))\n",
    "        for i in range(layers):\n",
    "            sequential.append(tf.keras.layers.Dense(nodes/(2**(i+1)), activation='relu'))\n",
    "            sequential.append(tf.keras.layers.Dropout(dropout))\n",
    "        sequential.append(tf.keras.layers.Dense(1,activation=tf.nn.sigmoid))\n",
    "        \n",
    "        NNmodel = tf.keras.models.Sequential(sequential)\n",
    "\n",
    "        NNmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "        NNmodel.fit(xtrain,ytrain,epochs=20,batch_size=10,validation_split=0.33, verbose=0)\n",
    "    \n",
    "        accuracy = NNmodel.evaluate(xtest,ytest)[1]*100\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    mean_accuracy = round(sum(accuracies) / len(accuracies),4)\n",
    "    print(f'New Iteration! Layers: {layers} Nodes: {nodes} Dropout: {dropout} \\nMean Accuracy: {mean_accuracy} %')\n",
    "    return -mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa308c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optNNmodel = minimize(optimal_model, [3,64,0.1], bounds=[(0,20),(0,1000),(0,1)], options={'maxiter': 10}, tol=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb0471",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-optNNmodel.fun)\n",
    "print(optNNmodel.x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
